{
    "1": {
        "inputs": {
            "image": "Êñ∞Âû£ÁªìË°£.jpeg",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "ËæìÂÖ•‰∫∫ËÑ∏"
        }
    },
    "2": {
        "inputs": {
            "image": "AllYourLife_pose.png",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "3": {
        "inputs": {
            "detect_hand": "disable",
            "detect_body": "enable",
            "detect_face": "disable",
            "resolution": 1024,
            "bbox_detector": "yolox_l.onnx",
            "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
            "image": [
                "2",
                0
            ]
        },
        "class_type": "DWPreprocessor",
        "_meta": {
            "title": "DWPose Estimator"
        }
    },
    "4": {
        "inputs": {
            "strength": 0.8,
            "start_percent": 0,
            "end_percent": 1,
            "positive": [
                "8",
                0
            ],
            "negative": [
                "9",
                0
            ],
            "control_net": [
                "5",
                0
            ],
            "image": [
                "3",
                0
            ]
        },
        "class_type": "ControlNetApplyAdvanced",
        "_meta": {
            "title": "Apply ControlNet (Advanced)"
        }
    },
    "5": {
        "inputs": {
            "control_net_name": "thibaud_xl_openpose.safetensors"
        },
        "class_type": "ControlNetLoaderAdvanced",
        "_meta": {
            "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
        }
    },
    "6": {
        "inputs": {
            "ckpt_name": "LEOSAM_HellowWorld_Lightning_6.0.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "7": {
        "inputs": {
            "stop_at_clip_layer": -1,
            "clip": [
                "6",
                1
            ]
        },
        "class_type": "CLIPSetLastLayer",
        "_meta": {
            "title": "CLIP Set Last Layer"
        }
    },
    "8": {
        "inputs": {
            "text": [
                "22",
                0
            ],
            "clip": [
                "7",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "9": {
        "inputs": {
            "text": "(long neck:1.5), (Exposed teeth, tooth, worst quality,low resolution, hands, hand), NSFW, nude, distorted, twisted, watermark, anime, cartoon, open mouth, ",
            "clip": [
                "7",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "21": {
        "inputs": {
            "Text": "(close mouth:1.5), (smile:1.2), ID photo, (looking at viewer:1.5), Fair and tender skin, (cold and fair skin:1.5), perfect face, realistic, Light makeup, beautiful eyes, smooth skin, (white T-shirt:1.5), white background, solid color background, "
        },
        "class_type": "DF_Text",
        "_meta": {
            "title": "ÈªòËÆ§ÊèèËø∞1"
        }
    },
    "22": {
        "inputs": {
            "string_a": [
                "21",
                0
            ],
            "string_b": [
                "69",
                0
            ]
        },
        "class_type": "ConcatStringSingle",
        "_meta": {
            "title": "Concat String (Single) üìÖüÖïüÖù"
        }
    },
    "23": {
        "inputs": {
            "seed": [
                "33",
                0
            ],
            "steps": 8,
            "cfg": 1.2000000000000002,
            "sampler_name": "euler_ancestral",
            "scheduler": "normal",
            "denoise": 1,
            "preview_method": "auto",
            "vae_decode": "true",
            "model": [
                "35",
                0
            ],
            "positive": [
                "35",
                1
            ],
            "negative": [
                "35",
                2
            ],
            "latent_image": [
                "24",
                0
            ],
            "optional_vae": [
                "6",
                2
            ]
        },
        "class_type": "KSampler (Efficient)",
        "_meta": {
            "title": "KSampler (Efficient)"
        }
    },
    "24": {
        "inputs": {
            "width": [
                "57",
                0
            ],
            "height": [
                "57",
                1
            ],
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "28": {
        "inputs": {
            "image": [
                "23",
                5
            ]
        },
        "class_type": "LayerUtility: GetImageSize",
        "_meta": {
            "title": "LayerUtility: GetImageSize"
        }
    },
    "29": {
        "inputs": {
            "panel_width": [
                "28",
                0
            ],
            "panel_height": [
                "28",
                1
            ],
            "fill_color": "white",
            "fill_color_hex": "#000000"
        },
        "class_type": "CR Color Panel",
        "_meta": {
            "title": "üåÅ CR Color Panel"
        }
    },
    "31": {
        "inputs": {
            "x": 0,
            "y": 0,
            "resize_source": false,
            "destination": [
                "29",
                0
            ],
            "source": [
                "65",
                0
            ],
            "mask": [
                "58",
                1
            ]
        },
        "class_type": "ImageCompositeMasked",
        "_meta": {
            "title": "ImageCompositeMasked"
        }
    },
    "33": {
        "inputs": {
            "min": 1,
            "max": 99999999999999
        },
        "class_type": "RandomInt",
        "_meta": {
            "title": "Random Int"
        }
    },
    "35": {
        "inputs": {
            "ip_weight": 1,
            "cn_strength": 0.8,
            "start_at": 0,
            "end_at": 1,
            "noise": 0,
            "combine_embeds": "average",
            "instantid": [
                "36",
                0
            ],
            "insightface": [
                "37",
                0
            ],
            "control_net": [
                "38",
                0
            ],
            "image": [
                "1",
                0
            ],
            "model": [
                "6",
                0
            ],
            "positive": [
                "4",
                0
            ],
            "negative": [
                "4",
                1
            ],
            "image_kps": [
                "56",
                0
            ]
        },
        "class_type": "ApplyInstantIDAdvanced",
        "_meta": {
            "title": "Apply InstantID Advanced"
        }
    },
    "36": {
        "inputs": {
            "instantid_file": "ip-adapter.bin"
        },
        "class_type": "InstantIDModelLoader",
        "_meta": {
            "title": "Load InstantID Model"
        }
    },
    "37": {
        "inputs": {
            "provider": "CUDA"
        },
        "class_type": "InstantIDFaceAnalysis",
        "_meta": {
            "title": "InstantID Face Analysis"
        }
    },
    "38": {
        "inputs": {
            "control_net_name": "InstantID/diffusion_pytorch_model.safetensors"
        },
        "class_type": "ControlNetLoaderAdvanced",
        "_meta": {
            "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
        }
    },
    "51": {
        "inputs": {
            "seed": [
                "33",
                0
            ],
            "steps": 8,
            "cfg": 1.5,
            "sampler_name": "euler_ancestral",
            "scheduler": "normal",
            "denoise": 0.7000000000000001,
            "preview_method": "auto",
            "vae_decode": "true",
            "model": [
                "35",
                0
            ],
            "positive": [
                "35",
                1
            ],
            "negative": [
                "35",
                2
            ],
            "latent_image": [
                "52",
                0
            ],
            "optional_vae": [
                "6",
                2
            ]
        },
        "class_type": "KSampler (Efficient)",
        "_meta": {
            "title": "KSampler (Efficient)"
        }
    },
    "52": {
        "inputs": {
            "pixels": [
                "31",
                0
            ],
            "vae": [
                "6",
                2
            ]
        },
        "class_type": "VAEEncode",
        "_meta": {
            "title": "VAE Encode"
        }
    },
    "53": {
        "inputs": {
            "images": [
                "74",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "ËæìÂá∫Âõæ"
        }
    },
    "56": {
        "inputs": {
            "side_length": 1280,
            "side": "Longest",
            "upscale_method": "nearest-exact",
            "crop": "disabled",
            "image": [
                "2",
                0
            ]
        },
        "class_type": "DF_Image_scale_to_side",
        "_meta": {
            "title": "Image scale to side"
        }
    },
    "57": {
        "inputs": {
            "image": [
                "56",
                0
            ]
        },
        "class_type": "LayerUtility: GetImageSize",
        "_meta": {
            "title": "LayerUtility: GetImageSize"
        }
    },
    "58": {
        "inputs": {
            "detail_range": 8,
            "black_point": 0.01,
            "white_point": 0.99,
            "process_detail": true,
            "image": [
                "65",
                0
            ]
        },
        "class_type": "LayerMask: RemBgUltra",
        "_meta": {
            "title": "LayerMask: RemBgUltra"
        }
    },
    "65": {
        "inputs": {
            "strength": 100,
            "brightness": 3,
            "contrast": 0,
            "saturation": 0,
            "red": -3,
            "green": -3,
            "blue": 2,
            "image": [
                "72",
                0
            ]
        },
        "class_type": "LayerColor: AutoAdjust",
        "_meta": {
            "title": "LayerColor: AutoAdjust"
        }
    },
    "69": {
        "inputs": {
            "query": "What is this?",
            "custom_query": "Describe the character's gender, hairstyle, and hair color and skin tone in English. Just describe these contents without the other modifiers or natural language. for example:1girl, long hair, balck hair, dark skin",
            "print_log": false,
            "model": [
                "70",
                0
            ],
            "image": [
                "1",
                0
            ]
        },
        "class_type": "Image2Text",
        "_meta": {
            "title": "Image to Text üêº"
        }
    },
    "70": {
        "inputs": {
            "model": "deepseek-vl-7b-chat",
            "device": "cuda",
            "low_memory": false
        },
        "class_type": "LoadImage2TextModel",
        "_meta": {
            "title": "Loader Image to Text Model üêº"
        }
    },
    "72": {
        "inputs": {
            "smooth": 5,
            "threshold": -10,
            "opacity": 100,
            "image": [
                "23",
                5
            ]
        },
        "class_type": "LayerFilter: SkinBeauty",
        "_meta": {
            "title": "LayerFilter: SkinBeauty"
        }
    },
    "74": {
        "inputs": {
            "temperature": 15,
            "image": [
                "51",
                5
            ]
        },
        "class_type": "LayerColor: ColorTemperature",
        "_meta": {
            "title": "LayerColor: ColorTemperature"
        }
    }
}